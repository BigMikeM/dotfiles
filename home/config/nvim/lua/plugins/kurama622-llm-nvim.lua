-- local tools = require "llm.tools"
-- return {
--   {
--     "Kurama622/llm.nvim",
--     opts = {
--       -- [[ Github Models ]]
--       url = "https://models.inference.ai.azure.com/chat/completions",
--       model = "gpt-4o",
--       api_type = "openai",
--       max_tokens = 8000,
--       temperature = 0.3,
--       top_p = 0.7,
--
--       prompt = "You are a helpful english software engineer.",
--
--       spinner = {
--         text = {
--           "î©±ó°§žó°§ž",
--           "ó°§žî©±ó°§ž",
--           "ó°§žó°§žî©±",
--           "ó°§žî©±ó°§ž",
--         },
--         hl = "Title",
--       },
--
--       prefix = {
--         user = { text = "ðŸ˜ƒ ", hl = "Title" },
--         assistant = { text = "ï’¸ ", hl = "Added" },
--       },
--
--       -- history_path = "/tmp/llm-history",
--       save_session = true,
--       max_history = 15,
--       max_history_name_length = 20,
--         -- stylua: ignore
--         keys = {
--         -- The keyboard mapping for the input window.
--         ["Input:Submit"] = { mode = "n", key = "<cr>" },
--         ["Input:Cancel"] = { mode = {"n", "i"}, key = "<C-c>" },
--         ["Input:Resend"] = { mode = {"n", "i"}, key = "<C-r>" },
--
--         -- only works when "save_session = true"
--         ["Input:HistoryNext"] = { mode = {"n", "i"}, key = "<C-j>" },
--         ["Input:HistoryPrev"] = { mode = {"n", "i"}, key = "<C-k>" },
--
--         -- The keyboard mapping for the output window in "split" style.
--         ["Output:Ask"] = { mode = "n", key = "i" },
--         ["Output:Cancel"] = { mode = "n", key = "<C-c>" },
--         ["Output:Resend"] = { mode = "n", key = "<C-r>" },
--
--         -- The keyboard mapping for the output and input windows in "float" style.
--         ["Session:Toggle"] = { mode = "n", key = "<leader>ac" },
--         ["Session:Close"] = { mode = "n", key = {"<esc>", "Q"} },
--         },
--
--       -- display diff [require by action_handler]
--       display = {
--         diff = {
--           layout = "vertical", -- vertical|horizontal split for default provider
--           opts = { "internal", "filler", "closeoff", "algorithm:patience", "followwrap", "linematch:120" },
--           provider = "mini_diff", -- default|mini_diff
--         },
--       },
--       app_handler = {
--         Ask = {
--           handler = tools.disposable_ask_handler,
--           opts = {
--             position = {
--               row = 2,
--               col = 0,
--             },
--             title = " Ask ",
--             inline_assistant = true,
--             language = "Chinese",
--
--             -- [optinal] set your llm model
--             url = "https://api.chatanywhere.tech/v1/chat/completions",
--             model = "gpt-4o-mini",
--             api_type = "openai",
--             fetch_key = function() return vim.env.CHAT_ANYWHERE_KEY end,
--
--             -- display diff
--             display = {
--               mapping = {
--                 mode = "n",
--                 keys = { "d" },
--               },
--               action = nil,
--             },
--             -- accept diff
--             accept = {
--               mapping = {
--                 mode = "n",
--                 keys = { "Y", "y" },
--               },
--               action = nil,
--             },
--             -- reject diff
--             reject = {
--               mapping = {
--                 mode = "n",
--                 keys = { "N", "n" },
--               },
--               action = nil,
--             },
--             -- close diff
--             close = {
--               mapping = {
--                 mode = "n",
--                 keys = { "<esc>" },
--               },
--               action = nil,
--             },
--           },
--         },
--       },
--     },
--     keys = {
--       { "<leader>ac", mode = "n", "<cmd>LLMSessionToggle<cr>" },
--       -- Your AI Tools Key mappings
--       { "<leader>ts", mode = "x", "<cmd>LLMAppHandler WordTranslate<cr>" },
--       -- | | |
--       -- your key mapping your mode tool name
--     },
--   },
-- }
return {
  -- -- [[ Github Models ]]
  -- url = "https://models.inference.ai.azure.com/chat/completions",
  -- model = "gpt-4o",
  -- api_type = "openai",
  -- max_tokens = 4096,
  -- temperature = 0.3,
  -- top_p = 0.7,
  --
  -- prompt = "You are a helpful, advanced software engineer.",
  --
  -- prefix = {
  --   user = { text = "ðŸ˜ƒ ", hl = "Title" },
  --   assistant = { text = "ï’¸  ", hl = "Added" },
  -- },
  --
  -- -- history_path = "/tmp/llm-history",
  -- save_session = true,
  -- max_history = 15,
  -- max_history_name_length = 20,
  --
  -- keys = {
  --   -- The keyboard mapping for the input window.
  --   ["Input:Submit"] = { mode = "n", key = "<cr>" },
  --   ["Input:Cancel"] = { mode = { "n", "i" }, key = "<C-c>" },
  --   ["Input:Resend"] = { mode = { "n", "i" }, key = "<C-r>" },
  --
  --   -- only works when "save_session = true"
  --   ["Input:HistoryNext"] = { mode = { "n", "i" }, key = "<C-j>" },
  --   ["Input:HistoryPrev"] = { mode = { "n", "i" }, key = "<C-k>" },
  --
  --   -- The keyboard mapping for the output window in "split" style.
  --   ["Output:Ask"] = { mode = "n", key = "i" },
  --   ["Output:Cancel"] = { mode = "n", key = "<C-c>" },
  --   ["Output:Resend"] = { mode = "n", key = "<C-r>" },
  --
  --   -- The keyboard mapping for the output and input windows in "float" style.
  --   ["Session:Toggle"] = { mode = "n", key = "<leader>ac" },
  --   ["Session:Close"] = { mode = "n", key = { "<esc>", "Q" } },
  --
  --   -- Scroll
  --   ["PageUp"] = { mode = { "i", "n" }, key = "<C-b>" },
  --   ["PageDown"] = { mode = { "i", "n" }, key = "<C-f>" },
  --   ["HalfPageUp"] = { mode = { "i", "n" }, key = "<C-u>" },
  --   ["HalfPageDown"] = { mode = { "i", "n" }, key = "<C-d>" },
  --   ["JumpToTop"] = { mode = "n", key = "gg" },
  --   ["JumpToBottom"] = { mode = "n", key = "G" },
  -- },
  -- Completion = {
  --   opts = {
  --     keymap = {
  --       virtual_text = {
  --         accept = {
  --           mode = "i",
  --           keys = "<A-a>",
  --         },
  --         next = {
  --           mode = "i",
  --           keys = "<A-n>",
  --         },
  --         prev = {
  --           mode = "i",
  --           keys = "<A-p>",
  --         },
  --       },
  --     },
  --   },
  -- },
}
